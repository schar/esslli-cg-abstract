%\begin{pre}
\documentclass[11pt,twocolumn,a4paper]{bqhatevwr}
\usepackage{etex,amsmath,mathtools,newtxtext,newtxmath,expex,natbib,tikz-qtree,bookmark,tree-dvips,fancyhdr}%
\usepackage[margin=1in]{geometry}
\usepackage{bussproofs}\EnableBpAbbreviations
\usepackage{wasysym}
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\pruf}[1]{\def\ScoreOverhang{0pt}\def\defaultHypSeparation{\hskip .25em}#1\DisplayProof}%
\newcommand{\lab}[1]{\RightLabel{\scriptsize #1}}
\newcommand{\pt}{\hspace{1pt}}
\newcommand{\ppt}{\hspace{2pt}}
\newcommand{\dt}{\pt.\ppt}
\renewcommand{\ra}{\ensuremath{\rightarrow}}
\usepackage{enumitem}
\setlist[itemize]{leftmargin=0pt}
\def\labelitemi{} 
\lingset{exskip=.5em}
\delimitershortfall=-1pt
\bibliographystyle{bqhatevwr}
\author[D.~Bumford \& S.~Charlow]{\spauthor{Dylan Bumford \\ \institute{NYU}} \AND
  \spauthor{Simon Charlow \\ \institute{Rutgers}} \AND
}
\title{Monadic dynamic semantics}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}
\fancyhead{} % clear all header fields
\fancyhead[RO,RE]{\bsf{\large Monadic dynamic semantics: side effects and scope}}
\fancyfoot{} % clear all footer fields
\fancyfoot[CO,CE]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
%\end{pre}
\begin{document}
\thispagestyle{fancy}
%\maketitle

\section{Overview}
%\begin{sec}
  \textbf{C}ontinuized \textbf{C}ombinatory \textbf{C}ategorial \textbf{G}rammars supplement traditional applicative categorial grammars with a small number of combinators that allow expressions to take scope over their compositional contexts \citep[e.g.][]{ShanBarker:2006, BarkerShan:2008, BarkerShan:2014}. Though CCCGs offer robust accounts of in-scope binding (ibid.), the treatment of dynamic binding (i.e.~cross-sentential and donkey anaphora) proposed in \citealt{BarkerShan:2008} overgenerates (\citealt{Charlow:2010}; see \citealt{BarkerShan:2014} for in-depth discussion). Conversely, the related theory of \citealt{Groote:2006} (which relies on continuations, but is not a CCG) handles dynamic binding elegantly, but does not offer any general account of scope-taking. In addition, both \citealt{BarkerShan:2008} and \citealt{Groote:2006} analyze dynamic binding by indefinites, but not by expressions such as \emph{exactly one linguist}, which differs in important ways \citep[cf.][]{KampReyle:1993}. %
	
  This paper presents an explicit CCCG account of dynamic binding inspired by the computer science notion of a \emph{monad} \citep[e.g.][]{Moggi:1989, Wadler:1992, Wadler:1994, Wadler:1995, Shan:2002}. Monads were developed as an abstraction for structuring extensions to the pure lambda calculus; they enable us to modularly add \emph{side effects} \citep[cf.][]{Shan:2005} to a programming language or natural language grammar. It is proposed that dynamic binding can be captured by recognizing two kinds of linguistic side effects: \textbf{state} and \textbf{nondeterminism}. State corresponds to the ability to introduce discourse referents, while nondeterminism means the ability to track multiple computations in parallel, which facilitates a referential treatment of indefinite expressions. %
	
  Concretely, a monad determines a pair of combinators \ab{\eta,\,\star}, one for wrapping values inside trivially effectful structures, and another for composing programs that may incur side effects. Our proposal is to replace the standard lifting and lowering operations of CCCGs with (respectively) $\star$ and $\eta$. Combined with some intuitive lexical entries, this has the automatic effect of producing a CCCG that countenances side effects. Crucially, given the underlying continuations-based scaffolding, the problem of integrating well-motivated combinatorial approaches to scope with insights from dynamic semantics reduces to finding a monad for state and nondeterminism. Though we focus on the case of dynamic binding here, any system of effects can be grafted onto a continuized CCG in this way.%
%\end{sec}

\section{Continuations}
%\begin{sec}
  Simplifying somewhat,\footnote{In particular, abstracting away from the multimodal presentation of \citealt{ShanBarker:2006, BarkerShan:2008, BarkerShan:2014}.}we take it that a standard CCCG consists of three polymorphic combinators, \bsf{Lift}, \bsf{Triv}, and \bsf{Scope}, in addition to the basic categorial slashes that encode forward and backward function application. These combinators are defined in Figure~\ref{fig1} (along with a characterization of the slashes' behavior). The inference rules make use of a type constructor $\textsf{K}$ parameterized by two concrete types. Formally, $\textsf{K}\,a\,r \Coloneqq r/(r/a)$; the $r/a$ argument to something of type $\textsf{K}\,a\,r$ is called its \emph{continuation}, and represents the denotation of its context. Intuitively, expressions with type $\textsf{K}\,a\,r$ behave like things of type $a$ within compositional contexts of type $r$, the `result type' of the computation. For example, extensional generalized quantifiers have type $\textsf{K}\,e\,t$, since they behave locally as individuals but quantify over constituents of type $t$.%

  As for semantics, \bsf{Lift} turns any expression into a function on its continuation; it is a polymorphic generalization of the familiar lifting procedure that converts individuals to the corresponding principal ultrafilters (cf.~\citealt{Montague:1974}). \bsf{Scope} defines the compositional process whereby two continuized expressions are combined, giving the left scope over the right. Finally, \bsf{Triv} is a trivial continuation (the identity function) used to delimit contexts of evaluation and expose underlying semantic values. \citealt{ShanBarker:2006} show that these three operations suffice to derive cases of inverse scope (that is, where an expression scopes over something to its left).%
\begin{figure*}
  \small
  \begin{subfigure}[b]{\textwidth}
    \[%
      \begin{array}{@{}c@{}}
        \begin{array}{c@{\hspace{2em}}c}
          \pruf{%
            \AXC{$\Gamma \vdash f : b/a~~$}
            \AXC{$~~\Delta \vdash e : a$}
            \lab{$/$}
            \BIC{$\Gamma \cdot \Delta \vdash f\,e : b$}
          }
          &
          \pruf{%
            \AXC{$\Delta \vdash e : a~~$}
            \AXC{$~~\Gamma \vdash f : a \backslash b$}
            \lab{$\backslash$}
            \BIC{$\Delta \cdot \Gamma \vdash f\,e : b$}
          }
        \end{array}
        \\
        \begin{array}{c@{\hspace{2em}}c@{\hspace{2em}}c@{\hspace{2em}}c}%
          \pruf{%
            \AXC{\vphantom{f}}
            \lab{\bsf{Triv}}
            \UIC{$\varepsilon \vdash \lambda x.\,x : a/a$}
          }
          &
          \pruf{%
            \AXC{\vphantom{f}}
            \lab{\bsf{Lift}}
            \UIC{$\varepsilon \vdash \lambda xk.\,k\,x: \textsf{K}\,a\,r / a$}%
          }
          &
          \pruf{%
            \AXC{\vphantom{f}}
            \lab{\bsf{Scope}}
            \UIC{%
              $\varepsilon \vdash \bsf{S} :
              (\textsf{K}\,b\,r / \textsf{K}\,a\,r) / \textsf{K}\,(b/a)\,r$
            }
            % \AXC{$\Delta \vdash m : \textsf{K}\,(b/a)\,r~~$}
            % \AXC{$~~\Gamma \vdash n : \textsf{K}\,a\,r$}
            % \lab{$\bsf{S}$}
            % \BIC{$\Delta \cdot \Gamma \vdash \bsf{S}\,m\,n : \textsf{K}\,b\,r$}
          }
        \end{array}
      \end{array}
    \]
		\caption{Continuized CCG without side effects, fixing a result type $r$.}%
		\label{fig1}
  \end{subfigure} \\[1em]
  \begin{subfigure}[b]{\textwidth}
    \[
      \begin{array}{c}
        \begin{array}{c@{\hspace{2em}}c}
          \pruf{%
          \AXC{$\Gamma \vdash f : b/a~~$}
          \AXC{$~~\Delta \vdash e : a$}
          \lab{$/$}
          \BIC{$\Gamma \cdot \Delta \vdash f\,e : b$}
          }
          &
          \pruf{%
          \AXC{$\Delta \vdash e : a~~$}
          \AXC{$~~\Gamma \vdash f : a \backslash b$}
          \lab{$\backslash$}
          \BIC{$\Delta \cdot \Gamma \vdash f\,e : b$}
          }
        \end{array}
        \\
        \begin{array}{c@{\hspace{2em}}c@{\hspace{2em}}c@{\hspace{2em}}c}%
          \pruf{%
          \AXC{\vphantom{f}}
          \lab{$\eta$}
          \UIC{$\varepsilon \vdash \eta : \textsf{M}\,a / a$}
          }
          &
          \pruf{%
          \AXC{\vphantom{f}}
          \lab{$\star$}
          \UIC{%
            $\varepsilon \vdash (\star) :
            \textsf{K}\,a\,\textsf{M}\,r / \textsf{M}\,a$
          }
          }
          &
          \pruf{%
          \AXC{\vphantom{f}}
          \lab{\bsf{Scope}}
          \UIC{%
            $\varepsilon \vdash \bsf{S} :
            (\textsf{K}\,b\,r / \textsf{K}\,a\,r) / \textsf{K}\,(b/a)\,r$
          }
          % \AXC{$\Delta \vdash m : \textsf{K}\,(b/a)\,r~~$}
          % \AXC{$~~\Gamma \vdash n : \textsf{K}\,a\,r$}
          % \lab{$\bsf{S}$}
          % \BIC{$\Delta \cdot \Gamma \vdash \bsf{S}\,m\,n : \textsf{K}\,b\,r$}
          }
        \end{array}
      \end{array}
    \]
    \caption{Continuized CCG with side effects, fixing a monad \ab{\textsf{M},\,\eta,\,\star} and a result type $r$.}%
    \label{fig2}
	\end{subfigure}
  \caption{%
    Continuized CCGs with and without side effects, for a fixed result type
    $r$, monad \ab{\textsf{M},\,\eta,\,\star}, and empty string $\varepsilon$ s.t.~$\varepsilon \cdot \Gamma = \Gamma \cdot \varepsilon = \Gamma$. In both grammars, $\bsf{S}\,m\,n \ceq \lambda k .\, m\,(\lambda f .\, n\,(\lambda x .\, k\,(f\,x)))$.%
  }
\end{figure*}
%\end{sec}

\section{Adding side effects}
%\begin{sec}
  Continuized grammars need not place inherent restrictions on $r$, the type of the context. For simple cases where only boolean scope-taking is at issue (cf.~\citealt{BarwiseCooper:1981}), we can set $r \Coloneqq t$. But in general, we may be interested in contexts that denote in richer semantic spaces, as is typically the case with questions, focus, attitude reports, dynamic updates, etc. In such cases, we enrich the return type to match the phenomenon of interest. % YASS

  We propose to model the sorts of semantic enrichments motivated by these phenomena using monads (\citealt{Wadler:1994, Liangetal}), which serve much the same purpose in capturing the semantics of programming language \emph{side effects} like IO\@. A monad is a triple \ab{\textsf{M},\,\eta,\,\star} of a type constructor \textsf{M}, an injection function $\eta$ of type $a \ra \textsf{M}\,a$ (given any type $a$), and a recipe for sequencing programs $\star$, of type $\textsf{M}\,a \ra (a \ra \textsf{M}\,b) \ra \textsf{M}\,b$ (given any types $a,b$).\footnote{The arrow is a syntactically idle type constructor, s.t.~$a \ra b$ is inhabited by functions from type-$a$ things to type-$b$ things.} The monadic functors $\eta$ and $\star$ are required to satisfy the following three \emph{monad laws}, which ensure that $\eta\,x$ represents a \emph{trivial} injection of $x$ into the monad (left and right unit), and that order of evaluation, but not relative embedding, matters for program sequencing (a form of associativity): %
	\begin{defi}%
		\label{defi:mlaw}
		For any monad \ab{\textsf{M},\,\eta,\,\star}:
		\[\begin{array}{l@{}r@{}l}
			\text{Left unit: }&\eta\,x \star k &{}= k\,x
			\\
			\text{Right unit: }&m \star \eta &{}= m
			\\
			\text{Associativity: }&(m \star k) \star c &{}= m \star \lambda x.\,k\,x \star c%
		\end{array}\]
	\end{defi}
	
  Monads provide an elegant bridge between side effects and continuations, because the type of $(\star)$ is equivalent to $\textsf{M}\,a \ra \textsf{K}\,a\,(\textsf{M}\,b)$. The sequencing function is thus itself a means of lifting effectful programs into continuized programs. Similarly, the injection function doubles as a default continuation, always available to be passed to $\textsf{K}\,a\,(\textsf{M}\,b)$ programs without generating any new side effects. In this way, we can construct continuized grammars directly from monads by trading in \bsf{Lift} for $\star$ and \bsf{Triv} for $\eta$ (Figure \ref{fig2}). Because \bsf{Scope} already operates at the level of continuized programs, it doesn't change.%	
	
  This setup entails a form of \emph{monadic functional application}, as in Fact \ref{mfa}. Moreover, \bsf{Lift} is a theorem of any monadic grammar, when we restrict the result type to $\textsf{M}\,r$. See Fact \ref{mlift}.%
	\begin{fact}\label{mfa}%
		$\begin{array}[t]{@{}r@{}l@{}}
			\bsf{S}\,((\star)\,m)\,&((\star)\,n)\,\eta 
			\\
			&{}= m \star \lambda f.\,n \star \lambda x.\,\eta\,(f\,x)%
			\\
		\end{array}$%
	\end{fact}
	\begin{fact}\label{mlift}%
    $\Gamma \vdash x : a \Rightarrow \Gamma \vdash \lambda k.\,k\,x : \textsf{K}\,a\,(\textsf{M}\,r)$%
		%\begin{proof}
		%	Successive applications of $\eta$, $\star$.
		%\end{proof}
	\end{fact}
	
%\end{sec}

\section{Finding the dynamic monad}
%\begin{sec}
  We treat dynamic semantics as a case study for the monadic approach. Following \citealt{Shan:2001}, we characterize dynamic systems as those that recognize some forms of mutable state and nondeterminism. The former provides a mechanism by which expressions can manipulate the discourse context, usually through the introduction of discourse referents. The latter guarantees that indefinites are handled on a par with referential expressions, but whose referents are generated ``randomly''.%\footnote{Dynamic treatments following \citealt{GroenendijkStokhof:1990} (e.g.~\citealt{Zimmermann:1991, Dekker:1993, Szabolcsi:2003, Groote:2006}) provide a way for indefinites to extend their binding domain but do not treat indefinites as nondeterministic analogs of proper names.}%
	
  In classic formulations of dynamic semantics (e.g.~\citealt{Heim:1982, Kamp:1981, GroenendijkStokhof:1991, Dekker:1994}), sentences denote relations on sequences. Non-empty relations correspond to truthful updates. Indefinites (and perhaps disjunctions) generate nonfunctional (in our terms, ``nondeterministic'') relations, with inputs matched against multiple outputs:%
  \begin{align}\notag%
	    \sv{\text{a linguist}} &= \lambda ki.\displaystyle\bigcup_{\mathclap{x\in\,\textsf{ling}}}k\,x\,(i + x)%
		\\
		\sv{\text{a linguist left}} &= \lambda i.\,\{i + x : x \in \textsf{ling} \wedge x \in \textsf{left}\}%
    \notag
  \end{align}%
  
  These denotations illustrate the way in which the standard dynamic approach puts state and nondeterminism front and center. Sentences are in fact \emph{nothing but} nondeterministic modifications of state; even truth and falsity are derivative notions. Sentential conjunction amounts to relation composition, which pipes the sequences output by the left conjunct pointwise into the right.%
  
  Borrowing from the functional programming literature, we advocate a different perspective: treating nondeterminism and state modification as \emph{side effects}, associated with semantic values, rather than replacing them. We pursue a monadic reformulation of dynamic semantics, by first locating a monad for state manipulation, and subsequently enriching it with nondeterminism. %
   
  Here, first, is the standard monad for state (Definition \ref{state}). Assume that $\gamma$ is the type of ``evaluation contexts''. For our purposes, we set $\gamma$ equal to the type of discourse referent (`dref') sequences.%
	\begin{defi}[The State monad]\label{state}
		\[\begin{array}[t]
			{@{}l@{}c@{}l@{}}
			\textsf{M}\,a &{}\Coloneqq{} &\gamma \ra a \ast \gamma	%
			\\
			\eta\,x &{}\ceq{} &\lambda i.\,\ab{x,\,i}
			\\
			m \star k &{}\ceq{} &\lambda i.\,k\,(m\,i)_0\,(m\,i)_1%
		\end{array}\]
	\end{defi}
	
  We model dref introduction as sequence extension \citep[cf.][]{Groote:2006, Unger:2012, Charlow:diss} and dref retrieval as sequence projection. To dynamically charge a monadic individual (of type $\textsf{M}\,e$), we pass the individual through a continuation that simply returns its underlying value and appends it to the output sequence (Definition~\ref{def:dref-intro}). To take a simple example, $(\eta\,\textsf{a})^\rhd  = \lambda i.\,\ab{\textsf{a},\,i+\textsf{a}}$.%
  
  Keeping things simple, we assume a single projection function $\cdot_\top$ that returns as its value the most topical referent (say, for concreteness, the last) in a sequence (Definition \ref{def:dref-get}).%
	\begin{defi}[Monadic dref introduction]
    \label{def:dref-intro}%
    	\[m^\rhd \ceq m \star \lambda xi.\,\eta\,x\,(i+x)\]
	\end{defi}
	\begin{defi}[State monad dref retrieval]
	\label{def:dref-get}
		\[\bsf{he} \ceq \lambda i.\,\ab{i_\top,\,i}\]
	\end{defi}
	
As an example, consider the sentence \emph{Al left} (call its denotation \bsf{X}). Al is first injected into the state monad with $\eta$, then shifted so as to introduce himself to the discourse record, then sequenced into a continuation representing his nuclear scope. The result is a function from states to truth if Al left and falsity if he didn't, paired with an updated state which now lists Al as a dref:%
	\[(\eta\,\textsf{a})^\rhd\! \star \lambda x.\,\eta\,(\textsf{left}\,x) = \lambda i.\,\ab{\textsf{left}\,\textsf{a},\,i+\textsf{a}}\]%
	
\noindent
Obversely, the sentence \emph{he was tired} (call its denotation \bsf{Y}) reads in a discourse state, chooses the most topical referent, and then returns the referent together with the original state, unmodified:%
	\[\bsf{he} \star \lambda x.\,\eta\,(\textsf{tired}\,x) = \lambda i.\,\ab{\textsf{tired}\,i_\top,\,i}\]%
	
\noindent
When we sequence the first sentence into the second (details anon), the dref introduced by \emph{Al} is immediately picked up by the pronoun: %
	\[\begin{array}{r@{}l}
		\bsf{X} \star \lambda p.\,\bsf{Y}&{}\star \lambda q.\,\eta\,(p \wedge q) %
		\\
		&{}= \lambda i.\,\ab{\textsf{left}\,\textsf{a} \wedge \textsf{tired}\,\textsf{a},\,i+\textsf{a}}%
	\end{array}\]
	
  The State monad treats discourse modification as a side effect of composition. To incorporate indefinites, which introduce drefs \emph{indeterminately}, we need (similarly to standard dynamic analyses) to add a layer of nondeterminism to the basic State monad. This we do in Definition~\ref{stateset}, which lays out what we will call the State-Set monad.\footnote{Also known as the Parser monad \citep{HuttonMeijer}.}%
	\begin{defi}[The State-Set monad]\label{stateset}
		\[\begin{array}[t]
			{@{}l@{}c@{}l@{}}
			\textsf{M}\,a &{}\Coloneqq{} &\gamma \ra (a \ast \gamma) \ra t%
			\\
			\eta\,x &{}\ceq{} &\lambda i.\,\{\ab{x,\,i}\}
			\\
			m \star k &{}\ceq{} &\lambda i.\displaystyle\bigcup_{\mathclap{\pi \in mi}}k\,\pi_0\,\pi_1%
		\end{array}\]
	\end{defi}

  Monadic meanings are now functions from discourse states to \emph{sets} of values, tagged with potentially updated output states. Sequential combination still pipes the output state of one program in as input to another, but it now does so pointwise. In the next section, we will see how this provides a robust effects regime for modeling dynamic binding. %

%\end{sec}

\section{Examples}
%\begin{sec}
  Figure~\ref{fig:lexicon} defines a small lexicon tailored for a CCCG built around the State-Set monad (e.g.~$\bsf{so} = \sv{\text{someone}}$). We argue that this grammar offers a powerful vantage point for analyzing dynamic phenomena that interact with patterns of scope-taking.%
  \begin{figure}
    \vspace{-1em}
    {\small\begin{align*}
      \bsf{john}    &\ceq \textsf{j}
                    &
      \bsf{so}      &\ceq \lambda i.\,\{\ab{x,\,i} \mid \textsf{human}\,x\}%
      \\
      \bsf{left}    &\ceq \textsf{left}%
                    &
      \bsf{he}      &\ceq \lambda i.\,\{\ab{i_\top,\,i}\}%
    \end{align*}
    \vspace{-3em}
    \begin{align*}
      \bsf{not}     &\ceq \lambda mi.\,\{\ab{\neg\exists \pi \in m\,i.\,\pi_0,\,i}\}%
      \\
      \bsf{a}       &\ceq \lambda ci.\,\{\ab{x,\,i'} \mid \ab{\textsf{True},\,i'} \in c\,x\,i\}%
      \\
      \bsf{every}   &\ceq \lambda ck.\,\bsf{not}\,(\bsf{a}\,c \star \lambda x.\,\bsf{not}\,(k\,x))%
      \\
      \bsf{eo} &\ceq \lambda k.\,\bsf{not}\,(\bsf{so} \star \lambda x.\,\bsf{not}\,(k\,x))%
      \\
      \bsf{nb} &\ceq \lambda k.\,\bsf{not}\,(\bsf{so} \star k)%	
    \end{align*}}
    \vspace{-2em}
		\caption{Lexicon specialized to State-Set Monad}%
    \label{fig:lexicon}%
  \end{figure}%
  
  These entries make no provisions for binding. Rather, dref introduction is treated modularly. We add a fourth and final combinator for generating a dref from a continuized expression (Definition \ref{def:ssbind}). See Fact \ref{fact:bindex} for an indication of how continuized dref introduction relates to monadic dref introduction.%
    \begin{defi}[Binding combinator]
	\label{def:ssbind}
  	\[
      \pruf{%
        \AXC{}
        \lab{$\RHD$}
        \UIC{$\varepsilon \vdash \lambda mk.\,m\,(\lambda xi.\,k\,x\,(i+x)) : \textsf{M}\,e/\textsf{M}\,e$}%
      }
      \]
    \end{defi}
	\begin{fact}\label{fact:bindex}
		$((\star)\,\bsf{so})^\RHD = \lambda k.\,\bsf{so}^\rhd\!\star k$
	\end{fact}
  
  Figure~\ref{fig:derivation} uses these tools to derive a case of cross-sentential anaphora. Notice that conjunction retains a static boolean semantics: since side effect composition is handled by the grammar, there is no reason to hard-code it into the semantics of sequencing. Relatedly, the predicates \emph{left} and \emph{tired} denote static $e \backslash t$ functions and interact with the monadic bits via $\eta$, $\star$, and \bsf{Scope}. A final property of the derivation worth highlighting is that both clauses are \emph{evaluated}, i.e.~applied to the default continuation $\eta$, before they are conjoined (the $\boxed{\text{boxes}}$ are simply intended to highlight this fact). This delimits the scope-taking of any expressions in the individual conjuncts, including that of the $\star$'d indefinite in the first sentence. In a manner of speaking, the indefinite hasn't been allowed to ``QR'' out of its clause. Nevertheless, its side effect --- the introduction of a nondeterministic dref --- lives on to influence the evaluation of the pronoun in the second conjunct. %
	\begin{figure*}
		%\begin{saveboxes}
		\newsavebox{\partbox}\setbox\partbox=\hbox{\scriptsize\pruf{%
				\AXC{$\bsf{so} : \textsf{M}\,e$}
				\lab{$\star$}
				\UIC{$\lambda k.\,\bsf{so} \star k : \textsf{K}\,e\,\textsf{M}\,t$}%
				\lab{$\RHD$}
				\UIC{$\lambda k.\,\bsf{so}^\rhd\! \star k : \textsf{K}\,e\,\textsf{M}\,t$}%
				\AXC{$\textsf{left} : e \backslash t$}
				\lab{$\uparrow$}
				\UIC{$\lambda k.\,k\,\textsf{left} : \textsf{K}\,(e \backslash t)\,\textsf{M}\,t$}%
				\lab{$\bsf{S}$}
				\BIC{$\lambda k.\,\bsf{so}^\rhd\! \star \lambda x.\,k\,(\textsf{left}\,x) : \textsf{K}\,t\,\textsf{M}\,t$}%
				\lab{$\downarrow$}
				\UIC{$\bsf{so}^\rhd\! \star \lambda x.\,\eta\,(\textsf{left}\,x) : \textsf{M}\,t$}%
				}}%
		\newsavebox{\partboxx}\setbox\partboxx=\hbox{\scriptsize\pruf{%
				\AXC{$\bsf{he} : \textsf{M}\,e$}
				\lab{$\star$}
				\UIC{$\lambda k.\,\bsf{he} \star k: \textsf{K}\,e\,\textsf{M}\,t$}%
				\AXC{$\textsf{tired} : e \backslash t$}
				\lab{$\uparrow$}
				\UIC{$\lambda k.\,k\,\textsf{tired} : \textsf{K}\,(e \backslash t)\,\textsf{M}\,t$}%
				\lab{$\bsf{S}$}
				\BIC{$\lambda k.\,\bsf{he} \star \lambda y.\,k\,(\textsf{tired}\,y) : \textsf{K}\,t\,\textsf{M}\,t$}%
				\lab{$\downarrow$}
				\UIC{$\bsf{he} \star \lambda y.\,\eta\,(\textsf{tired}\,y) : \textsf{M}\,t$}}}%
		%\end{saveboxes}
		{\small{\scriptsize\[\begin{array}{c}
			\pruf{%
			\AXC{$\boxed{\usebox\partbox}$}
			\lab{$\star$}
			\UIC{$\lambda k.\,\bsf{so}^\rhd\! \star \lambda x.\,k\,(\textsf{left}\,x) : \textsf{K}\,t\,\textsf{M}\,t$}%
			\AXC{$\textsf{and} : (t \backslash t)/t$}
			\lab{$\uparrow$}
			\UIC{$\lambda k.\,k\,\textsf{and} : \textsf{K}\,((t \backslash t)/t)\,\textsf{M}\,t$}%
			\AXC{$\boxed{\usebox\partboxx}$}
			\lab{$\star$}
			\UIC{$\lambda k.\,\bsf{he} \star \lambda y.\,k\,(\textsf{tired}\,y) : \textsf{K}\,t\,\textsf{M}\,t$}%
			\lab{$\bsf{S}$}
			\BIC{$\lambda k.\,\bsf{he} \star \lambda y.\,k\,(\lambda p.\,p \wedge \textsf{tired}\,y) : \textsf{K}\,(t \backslash t)\,\textsf{M}\,t$}%
			\lab{$\bsf{S}$}
			\BIC{$\lambda k.\,\bsf{so}^\rhd\! \star \lambda x.\,\bsf{he} \star \lambda y.\,k\,(\textsf{left}\,x \wedge \textsf{tired}\,y) : \textsf{K}\,t\,\textsf{M}\,t$}%
			\lab{$\downarrow$}
			\UIC{$\bsf{so}^\rhd\! \star \lambda x.\,\bsf{he} \star \lambda y.\,\eta\,(\textsf{left}\,x \wedge \textsf{tired}\,y) : \textsf{M}\,t$}%
			\lab{$\equiv$}
			\UIC{$\bsf{so}^\rhd\! \star \lambda x.\,\eta\,(\textsf{left}\,x \wedge \textsf{tired}\,x) : \textsf{M}\,t$}%
			}%
			\\[-1em]
		\end{array}\]}
		\caption{Deriving \emph{someone$_i$ left; he$_i$ was tired.} Some abbreviatory conventions are exploited: $\uparrow$ indicates sequential application of $\eta$ and $\star$ (i.e.~type-lifting, cf.~Fact \ref{mlift}), $\downarrow$ indicates that $\eta$ has been introduced and consumed (i.e.~lowering), and \bsf{S} stands in for both forward and backward continuized application (i.e.~\bsf{Scope}). Explicit combinator introduction is likewise suppressed in favor of inference labels.}%
		\label{fig:derivation}}
	\end{figure*}

  Other operators, however, may \emph{quantify} over the nondeterminism of indefinites in their scope, gobbling up their side effects in the process. Negation is the classic example. As defined in Figure~\ref{fig:lexicon}, $\bsf{not}$ evaluates its prejacent, discards any discourse referents generated in the process, and then checks that none of the alternative updates resulted in true boolean values. As is standard, we can use this state-capturing behavior to build up other dynamically closed meanings. For example, the universal quantifier \bsf{eo} ($=\sv{\text{everyone}}$) defined in Figure~\ref{fig:lexicon} will display quite different behavior than the indefinite of Figure~\ref{fig:derivation} when evaluated at the clause boundary. Plugging in the unit continuation will do two things: (i) as before, it will close off the nuclear scope of the universal; but (ii) this time, we will be left with a pure (effect-free) computation, equivalent to $\eta\,(\forall x.\,\textsf{human}\,x \Rightarrow \textsf{left}\,x)$. The same goes, mutatis mutandis, for \bsf{nb} ($= \sv{\text{nobody}}$).%

  Importantly, this does not preclude the possibility of donkey anaphora (e.g.~the classic \emph{every farmer who owns a donkey$_i$ beats it$_i$}). Returning to the lexical entry for \bsf{every}, note that the restrictor $c$ here acquires a kind of monadic scope, via $\star$, over the nuclear scope $k$. This means that any side effects inside $c$ will influence the context of evaluation for $k$. However, as in other dynamic systems, the wide-scoping negation will discharge whatever side effects are accrued in the process. %
%\end{sec}

\section{Discussion}
%\begin{sec}
	Monads thus offer a natural way to extend CCCGs with tools for dynamic binding. The combinatory apparatus we have proposed has four essential pieces: $\eta$, $\star$, $\RHD$, and \bsf{Scope}. Along with some intuitive lexical entries, this allows indefinites to extend their binding scope beyond the domain in which they are evaluated --- without recourse to dynamic conjunction, and within a completely standard model theory where ``contexts of evaluation'' are constructed on the fly (cf.~\citealt{Eijck:2001, Groote:2006}).%

	%This perspective differs from standard varieties of dynamic semantics, where only sentences are imbued with context change potential. Necessary since in PLA and standard dynamic treatments of anaphora, discourse-level content and truth-conditional content are conflated---i.e.~a sentence denotes a non-empty relation on sequences iff the sentence is true. Thus: standard dynamic techniques (DPL, DMG) not reducible to monads. %
	
	The theory can be scaled up in the usual ways to offer a robust characterization of a wide range of exceptional binding configurations, including dynamic binding by quantifiers such as \emph{exactly one linguist} (\citealt{Charlow:diss}). Moreover, though we lack the space to consider this here, the means by which indefinites extend their binding scope turns out to offer an immediate explanation for their ability to take ``quantificational'' scope out of scope islands (ibid.), and underlies an attractive dynamic account of functional quantification and pair-list phenomena (\citealt{Bumford:inc}). %
	
	As we indicated at the outset, the basic strategy at play here is quite general. Indeed, \emph{any} sufficiently ``well-behaved'' (see Definition \ref{defi:mlaw}) regime of semantic enrichment (e.g.~focus-sensitivity, alternative-generation, intensionality) may be accommodated along these lines. Furthermore, because of the inherent modularity of the monadic approach, various side effects may be added to or subtracted from the grammar without adjusting the basic compositional machinery or the lexical entries that are not sensitive to the effects in question. Therefore, we expect these results will be of interest for natural language semanticists of many stripes, in addition to categorial grammarians working on donkey anaphora and/or scope-taking. %  %% If a different, richer monad turns out to be motivated, we will need to change some lexical entries and swap out our core monadic functors $\eta$ and $\star$, but the basic shape of the grammar needn't change.
	
	%There is no need to settle on a single (``the'') grammar. Different and quite varied side effects regimes can be modularly grafted onto a simple applicative (``pure'') core. Lexical entries that would seem incongruous in a flat-footed standard perspective integrate seamlessly in a single grammar. Effects recognized in the types.  In the end: you have functional application, plus the functors from whichever monads are implicated in a given language. %
%\end{sec}

{\small\bibliography{bqhatevwr}}
\end{document}