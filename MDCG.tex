%\begin{pre}
\documentclass[11pt,twocolumn,a4paper]{bqhatevwr}
\usepackage{etex,amsmath,mathtools,newtxtext,newtxmath,expex,natbib,tikz-qtree,bookmark,tree-dvips}%
\usepackage[margin=1in]{geometry}
\usepackage{bussproofs}\EnableBpAbbreviations
\usepackage{wasysym}
\usepackage{caption}
\usepackage{subcaption}
\newcommand{\pruf}[1]{\def\ScoreOverhang{0pt}\def\defaultHypSeparation{\hskip .25em}#1\DisplayProof}%
\newcommand{\lab}[1]{\RightLabel{\scriptsize #1}}
\newcommand{\pt}{\hspace{1pt}}
\newcommand{\ppt}{\hspace{2pt}}
\newcommand{\dt}{\pt.\ppt}
\renewcommand{\ra}{\ensuremath{\shortrightarrow}}
\usepackage{enumitem}
\setlist[itemize]{leftmargin=0pt}
\def\labelitemi{} 
\lingset{exskip=.5em}
\delimitershortfall=-1pt
\bibliographystyle{bqhatevwr}
\author[D.~Bumford \& S.~Charlow]{\spauthor{Dylan Bumford \\ \institute{NYU}} \AND
  \spauthor{Simon Charlow \\ \institute{Rutgers}} \AND
}
\title{Monadic dynamic semantics}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\abovedisplayshortskip}{0pt}
\setlength{\belowdisplayshortskip}{0pt}
%\end{pre}
\begin{document}

%\maketitle

\section{Overview}
%\begin{sec}
  \textbf{C}ontinuized \textbf{C}ombinatory \textbf{C}ategorial \textbf{G}rammars supplement traditional applicative categorial grammars with a small number of combinators that allow expressions to take scope over their compositional contexts \citep[e.g.][]{ShanBarker:2006, BarkerShan:2008, BarkerShan:2014}. Though CCCGs offer robust accounts of in-scope binding (ibid.), the treatment of dynamic binding (i.e.~cross-sentential and donkey anaphora) proposed in \citealt{BarkerShan:2008} overgenerates (\citealt{Charlow:2010}; see \citealt{BarkerShan:2014} for in-depth discussion). Conversely, the related theory of \citealt{Groote:2006} (which relies on continuations, but is not a CCG) handles dynamic binding elegantly, but does not offer any general account of scope-taking. In addition, both \citealt{BarkerShan:2008} and \citealt{Groote:2006} analyze dynamic binding by indefinites, but not by expressions such as \emph{exactly one linguist}, which differs in important ways \citep[cf.][]{KampReyle:1993}. %
	
  This paper presents an explicit CCCG account of dynamic binding inspired by the computer science notion of a \emph{monad} \citep[e.g.][]{Moggi:1989, Wadler:1992, Wadler:1994, Wadler:1995, Shan:2002}. Monads were developed as an abstraction for structuring extensions to the pure lambda calculus; they enable us to modularly add \emph{side effects} \citep[cf.][]{Shan:2005} to a programming language or natural language grammar. It is proposed that dynamic binding can be captured by recognizing two kinds of linguistic side effects: \textbf{state} and \textbf{nondeterminism}. State corresponds to the ability to introduce discourse referents, while nondeterminism means the ability to track multiple computations in parallel, which facilitates a referential treatment of indefinite expressions. %
	
  Concretely, a monad determines a pair of combinators \ab{\eta,\,\star}, one for wrapping values inside trivially effectful structures, and another for composing programs with potential side effects. Our proposal is to replace the standard lifting and lowering operations of CCCGs with (respectively) $\star$ and $\eta$. Combined with some intuitive lexical entries, this has the automatic effect of producing a CCCG that countenances side effects. Crucially, given the underlying continuations-based scaffolding, the problem of integrating well-motivated combinatorial approaches to scope with insights from dynamic semantics reduces to finding a monad for state and nondeterminism. Though we focus on the case of dynamic binding here, any system of effects can be grafted onto a continuized CCG in this way.%
%\end{sec}

\section{Continuations}
%\begin{sec}
  Simplifying somewhat,\footnote{In particular, abstracting away from the multimodal presentation of \citealt{ShanBarker:2006, BarkerShan:2008, BarkerShan:2014}.}we take it that a standard CCCG consists of three polymorphic combinators, \bsf{Lift}, \bsf{Triv}, and \bsf{Scope}, in addition to the basic categorial slashes that encode forward and backward function application. These combinators are defined in Figure~\ref{fig1} (along with a characterization of the slashes' behavior). The inference rules make use of a type constructor $\textsf{K}$ parameterized by two concrete types. Formally, $\textsf{K}\,a\,r \Coloneqq r/(r/a)$; the $r/a$ argument to something of type $\textsf{K}\,a\,r$ is called its \emph{continuation}, and represents the denotation of its context. Intuitively, expressions with type $\textsf{K}\,a\,r$ behave like things of type $a$ within compositional contexts of type $r$, the `result type' of the computation. For example, extensional generalized quantifiers have type $\textsf{K}\,e\,t$, since they behave locally as individuals but quantify over constituents of type $t$.%

  As for combinators, \bsf{Lift} turns any expression into a function on its \emph{continuation}; it is a polymorphic generalization of the familiar lifting procedure that converts individuals to the corresponding principal ultrafilters (cf.~\citealt{Montague:1974}). \bsf{Scope} defines the compositional process whereby two continuized expressions are combined, giving the left scope over the right. Finally, \bsf{Triv} is a trivial continuation used to delimit contexts of evaluation and expose underlying semantic values. \citealt{ShanBarker:2006} show that these three operations suffice to derive cases of inverse scope (that is, where an expression scopes over something to its left).%
\begin{figure*}
  \small
  \begin{subfigure}[b]{\textwidth}
    \[%
      \begin{array}{@{}c@{}}
        \begin{array}{c@{\hspace{2em}}c}
          \pruf{%
            \AXC{$\Gamma \vdash f : b/a~~$}
            \AXC{$~~\Delta \vdash e : a$}
            \lab{$/$}
            \BIC{$\Gamma \cdot \Delta \vdash f\,e : b$}
          }
          &
          \pruf{%
            \AXC{$\Delta \vdash e : a~~$}
            \AXC{$~~\Gamma \vdash f : a \backslash b$}
            \lab{$\backslash$}
            \BIC{$\Delta \cdot \Gamma \vdash f\,e : b$}
          }
        \end{array}
        \\
        \begin{array}{c@{\hspace{2em}}c@{\hspace{2em}}c@{\hspace{2em}}c}%
          \pruf{%
            \AXC{\vphantom{f}}
            \lab{\bsf{Triv}}
            \UIC{$\varepsilon \vdash \lambda x.\,x : a/a$}
          }
          &
          \pruf{%
            \AXC{\vphantom{f}}
            \lab{\bsf{Lift}}
            \UIC{$\varepsilon \vdash \lambda xk.\,k\,x: \textsf{K}\,a\,r / a$}%
          }
          &
          \pruf{%
            \AXC{\vphantom{f}}
            \lab{\bsf{Scope}}
            \UIC{%
              $\varepsilon \vdash \bsf{S} :
              (\textsf{K}\,b\,r / \textsf{K}\,a\,r) / \textsf{K}\,(b/a)\,r$
            }
            % \AXC{$\Delta \vdash m : \textsf{K}\,(b/a)\,r~~$}
            % \AXC{$~~\Gamma \vdash n : \textsf{K}\,a\,r$}
            % \lab{$\sslash$}
            % \BIC{$\Delta \cdot \Gamma \vdash \bsf{S}\,m\,n : \textsf{K}\,b\,r$}
          }
        \end{array}
      \end{array}
    \]
		\caption{Continuized CCG without side effects, fixing a result type $r$.}%
		\label{fig1}
  \end{subfigure} \\[1em]
  \begin{subfigure}[b]{\textwidth}
    \[
      \begin{array}{c}
        \begin{array}{c@{\hspace{2em}}c}
          \pruf{%
          \AXC{$\Gamma \vdash f : b/a~~$}
          \AXC{$~~\Delta \vdash e : a$}
          \lab{$/$}
          \BIC{$\Gamma \cdot \Delta \vdash f\,e : b$}
          }
          &
          \pruf{%
          \AXC{$\Delta \vdash e : a~~$}
          \AXC{$~~\Gamma \vdash f : a \backslash b$}
          \lab{$\backslash$}
          \BIC{$\Delta \cdot \Gamma \vdash f\,e : b$}
          }
        \end{array}
        \\
        \begin{array}{c@{\hspace{2em}}c@{\hspace{2em}}c@{\hspace{2em}}c}%
          \pruf{%
          \AXC{\vphantom{f}}
          \lab{$\eta$}
          \UIC{$\varepsilon \vdash \eta : \textsf{M}\,a / a$}
          }
          &
          \pruf{%
          \AXC{\vphantom{f}}
          \lab{$\star$}
          \UIC{%
            $\varepsilon \vdash (\star) :
            \textsf{K}\,a\,\textsf{M}\,r / \textsf{M}\,a$
          }
          }
          &
          \pruf{%
          \AXC{\vphantom{f}}
          \lab{\bsf{Scope}}
          \UIC{%
            $\varepsilon \vdash \bsf{S} :
            (\textsf{K}\,b\,r / \textsf{K}\,a\,r) / \textsf{K}\,(b/a)\,r$
          }
          % \AXC{$\Delta \vdash m : \textsf{K}\,(b/a)\,r~~$}
          % \AXC{$~~\Gamma \vdash n : \textsf{K}\,a\,r$}
          % \lab{$\sslash$}
          % \BIC{$\Delta \cdot \Gamma \vdash \bsf{S}\,m\,n : \textsf{K}\,b\,r$}
          }
        \end{array}
      \end{array}
    \]
    \caption{Continuized CCG with side effects, fixing a monad \ab{\textsf{M},\,\eta,\,\star} and a result type $r$.}%
    \label{fig2}
	\end{subfigure}
  \caption{%
    Continuized CCGs with and without side effects, for a fixed result type
    $r$ and monad \ab{\textsf{M},\,\eta,\,\star}. In both grammars, $\bsf{S}\,m\,n \ceq \lambda k .\, m\,(\lambda f .\, n\,(\lambda x .\, k\,(f\,x)))$.
  }
\end{figure*}

%\end{sec}

\section{Adding side effects}
%\begin{sec}
  Continuized grammars need not place inherent restrictions on $r$, the type of the context. For simple cases where only boolean scope-taking is at-issue (cf.~\citealt{BarwiseCooper:1981}), we can set $r \Coloneqq t$. But in general, we may be interested in contexts that denote in richer semantic spaces, as is typically the case with questions, focus, attitude reports, dynamic updates, etc. In such cases, we enrich the return type to match the phenomenon of interest. % YASS

  We propose to model the sorts of semantic enrichments motivated by these phenomena using monads (\citealt{Wadler:1994, Liangetal}), which serve much the same purpose in capturing the semantics of programming language \emph{side effects} like IO\@. A monad is a triple \ab{\textsf{M},\,\eta,\,\star} of a type constructor \textsf{M}, an injection function $\eta$ of type $a \ra \textsf{M}\,a$ (given any type $a$), and a recipe for sequencing programs $\star$, of type $\textsf{M}\,a \ra (a \ra \textsf{M}\,b) \ra \textsf{M}\,b$ (given any types $a,b$). The monadic functors $\eta$ and $\star$ are required to satisfy the following three \emph{monad laws}, which ensure that $\eta\,x$ represents a \emph{trivial} injection of $x$ into the monad (left and right unit), and that order of evaluation, but not relative embedding, matters for program sequencing (a form of associativity): %
	\begin{defi}%
		For any monad \ab{\textsf{M},\,\eta,\,\star}:
		\[\begin{array}{l@{}r@{}l}
			\text{Left unit: }&\eta\,x \star k &{}= k\,x
			\\
			\text{Right unit: }&m \star \eta &{}= m
			\\
			\text{Associativity: }&(m \star k) \star c &{}= m \star \lambda x.\,k\,x \star c%
		\end{array}\]
	\end{defi}
	
  Monads provide an elegant bridge between side effects and continuations, because the type of $(\star)$ is equivalent to $\textsf{M}\,a \ra \textsf{K}\,a\,(\textsf{M}\,b)$. The bind function is thus itself a means of lifting effectful programs into continuized programs. Similarly, the unit function doubles as a default continuation, always available to be passed to $\textsf{K}\,a\,(\textsf{M}\,b)$ programs without generating any new side effects. In this way, we can construct continuized grammars directly from monads by trading in \bsf{Lift} for $\star$ and \bsf{Triv} for $\eta$. Conveniently, because \bsf{Scope} operates at the level of already continuized programs, it doesn't change.%	
	
  In fact, \bsf{Lift} is a theorem of any monadic grammar, when we restrict the result type to $\textsf{M}\,r$. Generally, for any monad \ab{\textsf{M},\,\eta,\,\star} and result type $r$:%
	\begin{fact}%
    $\Gamma \vdash x : a \Rightarrow \Gamma \vdash \lambda k.\,k\,x : \textsf{K}\,a\,(\textsf{M}\,r)$%
		%\begin{proof}
		%	Successive applications of $\eta$, $\star$.
		%\end{proof}
	\end{fact}
	\begin{fact}%
		$\begin{array}[t]{@{}r@{}l@{}}
			\bsf{S}\,((\star)\,m)\,&((\star)\,n)\,\eta 
			\\
			&{}= m \star \lambda f.\,n \star \lambda x.\,\eta\,(f\,x)%
			\\
		\end{array}$%
	\end{fact}
%\end{sec}

\section{Finding the dynamic monad}
%\begin{sec}
  We treat dynamic semantics as a case study for the monadic approach. Following \citet{Shan:2001}, we characterize dynamic systems as those that recognize some forms of mutable state and nondeterminism. The former provides a mechanism by which expressions can manipulate the discourse context, usually through the introduction of discourse referents. The latter guarantees that indefinites are handled on a par with referential expressions, but whose referents are generated ``randomly''.%\footnote{Dynamic treatments following \citealt{GroenendijkStokhof:1990} (e.g.~\citealt{Zimmermann:1991, Dekker:1993, Szabolcsi:2003, Groote:2006}) provide a way for indefinites to extend their binding domain but do not treat indefinites as nondeterministic analogs of proper names.}%
	
  In classic formulations of dynamic semantics (\citealt{Heim:1982, Kamp:1981, GroenendijkStokhof:1991, Dekker:1994}), sentences denote relations on sequences. Non-empty relations correspond to truthful updates. Indefinites (and perhaps disjunctions) generate nonfunctional (in our terms, ``nondeterministic'') relations, with inputs matched against multiple outputs. Sentential conjunction amounts to relation composition, which pipes the sequences output by the left conjunct pointwise into the right.%
  \begin{align}%
    \label{eq:classic-indef}%
		\sv{\text{someone}} &= \lambda ki.\displaystyle\bigcup_{\mathclap{x\in\,\textsf{person}}}k\,x\,(i + x)%
		\\
		\sv{\text{someone left}} &= \lambda i.\,\{i + x : x \in \textsf{person} \wedge x \in \textsf{left}\}%
    \notag
  \end{align}%

  The denotations in (\ref{eq:classic-indef}) illustrate the way in which the standard dynamic approach puts state and nondeterminism are put front and center. Sentences are in fact \emph{nothing but} nondeterministic modifications of state; even truth and falsity are derivative notions. Borrowing from the functional programming literature, we advocate a different perspective: treating nondeterminism and state modification as \emph{side effects}, associated with semantic values, rather than replacing them. 
	
  Here is the standard monad for state manipulation. Assume that $\gamma$ is the type of ``evaluation contexts''. For our purposes, we set $\gamma$ equal to the type of discourse referent sequences.%
	\begin{defi}[The State monad]\label{state}
		\[\begin{array}[t]
			{@{}l@{}c@{}l@{}}
			\textsf{M}\,a &{}\Coloneqq{} &\gamma \ra a \ast \gamma	%
			\\
			\eta\,x &{}\ceq{} &\lambda i.\,\ab{x,\,i}
			\\
			m \star k &{}\ceq{} &\lambda i.\,k\,(m\,i)_0\,(m\,i)_1%
		\end{array}\]
	\end{defi}
	
  To keep things simple, we model dref introduction as sequence extension \citep[cf.][]{Groote:2006, Unger:2012, Charlow:diss} and dref retrieval as sequence projection. To dynamically charge a monadic individual (of type $\textsf{M}\,e$), we pass the individual through a continuation that simply returns its underlying value and appends it to the output sequence (Definition~\ref{def:dref-intro}). For instance $(\eta\,\textsf{j})^\rhd \star \lambda xi.\,\ab{x,\,i+x} = \lambda i.\,\ab{\textsf{j},\,i+\textsf{j}}$.
  
  Again keeping things simple, we assume a single projection function $\cdot_\top$ that returns as its value the most topical referent (say, for concreteness, the last) in a sequence.
	\begin{defi}[Dref introduction]
    \label{def:dref-intro}%
    \[m^\rhd \ceq m \star \lambda x.\,\eta\,x\,(i+x)\]
	\end{defi}
	\begin{defi}[Dref retrieval]
		\[\bsf{he} \ceq \lambda i.\,\ab{i_\top,\,i}\]
	\end{defi}
	
\noindent
As an example, consider the sentence \emph{Al left} (call its denotation \bsf{X}). Al is first injected into the state monad with $\eta$, then shifted so as to introduce himself to the discourse record, then sequenced into a continuation representing his nuclear scope. The result is a function from states to truth if Al left and falsity if he didn't, paired with an updated state which now lists Al as a dref.
	\[(\eta\,\textsf{a})^\rhd\! \star \lambda x.\,\eta\,(\textsf{left}\,x) = \lambda i.\,\ab{\textsf{left}\,\textsf{a},\,i+\textsf{a}}\]%
	
\noindent
Obversely, the sentence \emph{he was tired} (call its denotation \bsf{Y}) reads in a discourse state, chooses the most topical referent in that state, and then returns the referent together with the original state, unmodified.
	\[\bsf{he} \star \lambda x.\,\eta\,(\textsf{tired}\,x) = \lambda i.\,\ab{\textsf{tired}\,i_\top,\,i}\]%
	
\noindent
When we sequence the first sentence into the second, the dref introduced by the proper name is immediately picked up by the pronoun. 
\vspace{-1.5em}
	\[\begin{array}{r@{}l}
		\bsf{X} \star \lambda p.\,\bsf{Y}&{}\star \lambda q.\,\eta\,(p \wedge q) %
		\\
		&{}= \lambda i.\,\ab{\textsf{left}\,\textsf{a} \wedge \textsf{tired}\,\textsf{a},\,i+\textsf{a}}%
	\end{array}\]
	
  Thus the State monad allows us to see discourse modification as a side effect of composition. However, to incorporate indefinites, which introduce drefs \emph{indeterminately}, we need to add a layer of nondeterminism to the basic State monad. This we do in Definition~\ref{stateset}, which lays out what we will call the State-Set monad.\footnote{Also known as the Parser monad \citep{HuttonMeijer}.}%
	\begin{defi}[The State-Set monad]\label{stateset}
		\[\begin{array}[t]
			{@{}l@{}c@{}l@{}}
			\textsf{M}\,a &{}\Coloneqq{} &\gamma \ra (a \ast \gamma) \ra t%
			\\
			\eta\,x &{}\ceq{} &\lambda i.\left\{\ab{x,\,i}\right\}
			\\
			m \star k &{}\ceq{} &\lambda i.\displaystyle\bigcup_{\mathclap{\pi \in mi}}k\,\pi_0\,\pi_1%
		\end{array}\]
	\end{defi}

  Monadic meanings are now functions from discourse states to \emph{sets} of values, tagged with potentially updated output states. Sequential combination still pipes the output state of one program in as input to another, but it now does so pointwise. In the next section, we will see how this provides a robust effects regime for modeling dynamic binding. Finally, to round out the formal fragment, we define a fourth combinator that shifts a State-Set monadic update into a dref-introducing update.
  \[
    \pruf{%
      \AXC{\vphantom{f}}
      \lab{$\RHD$}
      \UIC{$\varepsilon \vdash \lambda mk.\,m\,(\lambda xi.\,k\,x\,(i+x)) : \textsf{M}\,e/\textsf{M}\,e$}
    }
  \]
%\end{sec}

\section{Examples}
%\begin{sec}
  Figure~\ref{fig:lexicon} defines a small lexicon tailored for a CCCG built around the State-Set monad. We argue that this grammar offers a powerful vantage point for analyzing dynamic phenomena that interact with patterns of scope-taking.%
  \begin{figure}
    \vspace{-1em}
    {\small\begin{align*}
      \bsf{john}    &\ceq \textsf{j}
                    &
      \bsf{so}      &\ceq \lambda i.\,\{\ab{x,\,i} \mid \textsf{person}\,x\}
      \\
      \bsf{left}    &\ceq \textsf{left}%
                    &
      \bsf{he}      &\ceq \lambda i.\,\{\ab{i_\top,\,i}\}%
    \end{align*}
    \vspace{-3em}
    \begin{align*}
      \bsf{not}     &\ceq \lambda mi.\left\{\ab{\neg\exists \pi \in m\,i.\,\pi_0,\,i}\right\}%
      \\
      \bsf{a}       &\ceq \lambda ci.\,\{\ab{x,\,i'} \mid \ab{\textsf{T},\,i'} \in c\,x\,i\}%
      \\
      \bsf{every}   &\ceq \lambda ck.\,\bsf{not}\,(\bsf{a}\,c \star \lambda x.\,\bsf{not}\,(k\,x))%
      \\
      \bsf{ev.ling} &\ceq \lambda k.\,\bsf{not}\,(\bsf{a.ling} \star \lambda x.\,\bsf{not}\,(k\,x))%
      \\
      \bsf{no.ling} &\ceq \lambda k.\,\bsf{not}\,(\bsf{a.ling} \star k)%	
    \end{align*}}
    \vspace{-2em}
		\caption{Lexicon for CCCG specialized to State-Set Monad}%
    \label{fig:lexicon}%
  \end{figure}%
  
  For instance, Figure~\ref{fig:derivation} provides a derivation of cross-sentential anaphora. One property of the derivation worth highlighting is that both clauses are evaluated, i.e. applied to the default $\eta$ continuation, before they are conjoined. This delimits the scope of quantificational operators in the clauses, including that of the indefinite in the first sentence. Nevertheless, the indefinite's side effect --- its introduction of a nondeterministic discourse referent --- lives on to influence the evaluation of the pronoun in the second conjunct.

	\begin{figure*}
		%\begin{saveboxes}
		\newsavebox{\partbox}\setbox\partbox=\hbox{\scriptsize\pruf{%
				\AXC{$\bsf{so} : \textsf{M}\,e$}
				\lab{$\star$}
				\UIC{$\lambda k.\,\bsf{so} \star k : \textsf{K}\,e\,\textsf{M}\,t$}%
				\lab{$\RHD$}
				\UIC{$\lambda k.\,\bsf{so}^\rhd\! \star k : \textsf{K}\,e\,\textsf{M}\,t$}%
				\AXC{$\textsf{left} : e \backslash t$}
				\lab{$\uparrow$}
				\UIC{$\lambda k.\,k\,\textsf{left} : \textsf{K}\,(e \backslash t)\,\textsf{M}\,t$}%
				\lab{$\bbslash$}
				\BIC{$\lambda k.\,\bsf{so}^\rhd\! \star \lambda x.\,k\,(\textsf{left}\,x) : \textsf{K}\,t\,\textsf{M}\,t$}%
				\lab{$\downarrow$}
				\UIC{$\bsf{so}^\rhd\! \star \lambda x.\,\eta\,(\textsf{left}\,x) : \textsf{M}\,t$}%
				}}%
		\newsavebox{\partboxx}\setbox\partboxx=\hbox{\scriptsize\pruf{%
				\AXC{$\bsf{he} : \textsf{M}\,e$}
				\lab{$\star$}
				\UIC{$\lambda k.\,\bsf{he} \star k: \textsf{K}\,e\,\textsf{M}\,t$}%
				\AXC{$\textsf{tired} : e \backslash t$}
				\lab{$\uparrow$}
				\UIC{$\lambda k.\,k\,\textsf{tired} : \textsf{K}\,(e \backslash t)\,\textsf{M}\,t$}%
				\lab{$\bbslash$}
				\BIC{$\lambda k.\,\bsf{he} \star \lambda y.\,k\,(\textsf{tired}\,y) : \textsf{K}\,t\,\textsf{M}\,t$}%
				\lab{$\downarrow$}
				\UIC{$\bsf{he} \star \lambda y.\,\eta\,(\textsf{tired}\,y) : \textsf{M}\,t$}}}%
		%\end{saveboxes}
		{\small{\scriptsize\[\begin{array}{c}
			\pruf{%
			\AXC{$\boxed{\usebox\partbox}$}
			\lab{$\star$}
			\UIC{$\lambda k.\,\bsf{so}^\rhd\! \star \lambda x.\,k\,(\textsf{left}\,x) : \textsf{K}\,t\,\textsf{M}\,t$}%
			\AXC{$\textsf{and} : (t \backslash t)/t$}
			\lab{$\uparrow$}
			\UIC{$\lambda k.\,k\,\textsf{and} : \textsf{K}\,((t \backslash t)/t)\,\textsf{M}\,t$}%
			\AXC{$\boxed{\usebox\partboxx}$}
			\lab{$\star$}
			\UIC{$\lambda k.\,\bsf{he} \star \lambda y.\,k\,(\textsf{tired}\,y) : \textsf{K}\,t\,\textsf{M}\,t$}%
			\lab{$\sslash$}
			\BIC{$\lambda k.\,\bsf{he} \star \lambda y.\,k\,(\lambda p.\,p \wedge \textsf{tired}\,y) : \textsf{K}\,(t \backslash t)\,\textsf{M}\,t$}%
			\lab{$\bbslash$}
			\BIC{$\lambda k.\,\bsf{so}^\rhd\! \star \lambda x.\,\bsf{he} \star \lambda y.\,k\,(\textsf{left}\,x \wedge \textsf{tired}\,y) : \textsf{K}\,t\,\textsf{M}\,t$}%
			\lab{$\downarrow$}
			\UIC{$\bsf{so}^\rhd\! \star \lambda x.\,\bsf{he} \star \lambda y.\,\eta\,(\textsf{left}\,x \wedge \textsf{tired}\,y) : \textsf{M}\,t$}%
			\lab{$\equiv$}
			\UIC{$\bsf{so}^\rhd\! \star \lambda x.\,\eta\,(\textsf{left}\,x \wedge \textsf{tired}\,x) : \textsf{M}\,t$}%
			}%
			\\[-1em]
		\end{array}\]}
		\caption{Cross-sentential anaphora: deriving \emph{someone$_i$ left; he$_i$ was tired.}}%
		\label{fig:derivation}}
	\end{figure*}

  Other operators, however, may \emph{quantify} over the nondeterminism of indefinites in their scope, gobbling up their side effects in the process. Negation is the classic example. As defined in Figure~\ref{fig:lexicon}, $\bsf{not}$ evaluates its prejacent, discards any discoure referents generated in the process, and then checks that none of the alternative updates resulted in true boolean values. As is standard in dynamic systems, we can use this state-capturing behavior to build up other dynamically closed meanings. For example, the universal quantifier defined in Figure~\ref{fig:lexicon} will display quite different behavior than the indefinite of Figure~\ref{fig:derivation} when evaluated at the clause boundary. Plugging in the unit continuation will do two things: (i) as before, it will close off the nuclear scope of the universal; but (ii) this time, we will be left with a pure (effect-free) computation, equivalent to $\eta\,(\forall x.\,\textsf{person}\,x \Rightarrow \textsf{left}\,x)$.

  Importantly this does not preclude the possibility of donkey anaphora. Returning to the lexical entry for \bsf{every}, note that the restrictor $c$ here acquires a kind of monadic scope, via $\star$, over the nuclear scope $k$. This means that any side effects inside $c$ will influence the context of evaluation for $k$. However, as in other dynamic systems, the wide-scoping negation will discharge whatever side effects are accrued in the process. %
%\end{sec}

\section{Discussion}
%\begin{sec}
	Compare PLA, where only sentences are imbued with context change potential. Necessary since in PLA and standard dynamic treatments of anaphora, discourse-level content and truth-conditional content are conflated---i.e.~a sentence denotes a non-empty relation on sequences iff the sentence is true. Thus: standard dynamic techniques (DPL, DMG) not reducible to monads. %
	
	Some upshots: no dynamic conjunction, completely standard model theory (cf.~\citealt{Groote:2006}). ``Contexts of evaluation'' are constructed on the fly. Variable-free, directly compositional (\citealt{Jacobson:1999}). %

	Monads as a natural way to extend a continuations-based grammar with tools for dynamic binding and exceptional scope. In the end: you have functional application, plus the functors from whichever monads are implicated in a given language. Effects recognized in the types. %

	There is no need to settle on a single (``the'') grammar. Different and quite varied side effects regimes can be modularly grafted onto a simple applicative (``pure'') core. Lexical entries that would seem incongruous in a flat-footed standard perspective integrate seamlessly in a single grammar. %
	
	Again, any sufficiently ``well-behaved'' (see Section~\ref{?}) regime of semantic enrichment (e.g.~focus-sensitivity, alternative-generation, intensionality) may be accommodated along similar lines. Furthermore, because of the inherent modularity of the monadic approach, various side effects may be added to or subtracted from the grammar without adjusting the basic compositional machinery or the lexical entries that are not sensitive to the effects in question. Therefore, we expect these results will be of interest for natural language semanticists of many stripes, in addition to categorial grammarians working on donkey anaphora and/or scope-taking. % SC: moved here from S1
	
	Theory extends to scope islands, wide range of exceptional binding configurations \citealt{Charlow:diss}. Extends to pair-list phenomena, functional quantification: \citealt{Bumford:inc}. Crossover, superiority less clear (cf.~\citealt{ShanBarker:2006, BarkerShan:2008}). %
%\end{sec}

{\small\bibliography{bqhatevwr}}
\end{document}
